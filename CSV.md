# Загрузка CSV файлов в InterSystems IRIS

Не секрет, что несмотря на большое количество различных форматов хранения данных, CSV остаётся если не лидирующим, то, по крайней мере крупным игроком на этом рынке. Человекочитаемость (по сравнению с AVRO и Apache Parquet) и компактность (по сравнению с JSON и XML) а также простота генерации делают его популярным выбором как формата обмена данных для огромного количества информационных систем. InterSystems IRIS не является исключением, предоставляя ряд возможностей экспорта/импорта в CSV. Но в версии 2021.2 появилась новая SQL-функция [LOAD DATA](https://docs.intersystems.com/iris20212/csp/docbook/DocBook.UI.Page.cls?KEY=RSQL_loaddata) позволяющая легко загружать CSV файлы (и не только) в хранимые таблицы InterSystems IRIS. Об этом новом методе (с небольшим обзором других подходов) и будет эта статья.

# LOAD DATA 

Команда ```LOAD DATA``` загружает данные из источника данных в таблицу InterSystems IRIS. Источником может быть CSV файл или таблица во внешней СУБД, доступ к которой осуществляется по протоколу JDBC.

Эта команда предназначена для быстрого заполнения таблиц. Когда вы загружаете данные, %ROWCOUNT показывает количество успешно загруженных записей. Ошибка во входных данных приводит к тому, что эта запись не загружается, и загрузка переходит к следующей записи. SQLCODE не сообщает об этом как об ошибке; в журнале ```%SQL_Diag.Result``` указывается, сколько записей не удалось загрузить.

Если таблица, в которую загружаются данные пуста, LOAD DATA заполняет таблицу строками исходных данных. Если таблица уже содержит данные, LOAD DATA добавляет строки исходных данных к существующим данным.

Примечание: Команда LOAD DATA использует Java шлюз. Перед выполнением команды LOAD DATA на сервере должна быть установлена виртуальная машина Java (JVM). Вы также должны установить соединение ([External Language Server](https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=BJAVNAT_gateway#BJAVNAT_gateway_intro)) с сервером  Java. Это соединение запускается автоматически при первом использовании командой LOAD DATA.

Примечание: в превью версии 2021.2.0.617 необходимо отредактировать ```%Java Server``` и добавить аргумент JVM: `-Dfile.encoding=UTF-8`. В новых версиях этого делать не нужно.

## Определение команды:

```
LOAD DATA FROM FILE filepath 
    [ COLUMNS (fieldname datatype, fieldname2 datatype2, ...) ] 
INTO table [ (fieldname, fieldname2, ...) 
    [ VALUES (headeritem,headeritem2, ...) ] ]
    [ USING {json_object} ]

LOAD DATA FROM JDBC connection TABLE jtable
INTO table [ (fieldname, fieldname2, ...) 
    [ VALUES (jfieldname,jfieldname2, ...) ] ]
```

| Аргумент                        | Описание                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| filepath                        | (Только для файлов) Путь к файлу на сервере в кавычках.                                                                                                                                                                                                                                                                                                                                                                                                    |
| COLUMNS (fieldname datatype)    | (Опционально, только для файлов) Последовательность колонок в файле и их типы данных                                                                                                                                                                                                                                                                                                                                                                        |
| INTO table                      | Таблица, в которую будут загружены данные. Имя таблицы может быть квалифицированным (schema.tablename) или неквалифицированным (tablename). Неквалифицированное имя таблицы принимает имя схемы по умолчанию. Можно указать представление для загрузки данных в таблицу, доступ к которой осуществляется через представление.                                                                                                                               |
| (fieldname,fieldname)           | (Опционально) Поля таблицы для загрузки данных файла, указанные в порядке следования полей данных файла. Этот список имен полей позволяет указать выбранные поля таблицы и согласовать порядок элементов файла данных с полями в таблице. Поле, которое не указано, принимает значение по умолчанию, если оно указано в определении таблицы. Если этот пункт опущен, все поля таблицы, определенные пользователем, должны быть представлены в файле данных. |
| VALUES (headeritem,headeritem2) | (Опционально) Для источника файла данных - имена заголовков файла данных (headeritem) или имена COLUMNS. Для источника данных JDBC - имена столбцов таблицы JDBC (jfieldname). Элементы должны позиционно соответствовать именам полей в INTO.                                                                                                                                                                                                              |
| USING {json\_object}            | (Опционально) Параметры загрузки для входного файла данных, используя синтаксис вложенной пары ключ:значение объекта JSON. Например, USING {"from":{"file":{"columnseparator":"^"}}}. Используется для указания символа-разделителя столбцов файла исходных данных, наличия строки заголовка файла исходных данных и других параметров. Если пункт USING не указан, используются параметры нагрузки по умолчанию.                                           |
| connection                      | (Только для JDBC) Имя SQL Gateway Connection                                                                                                                                                                                                                                                                                                                                                                                                                |
| TABLE jtable                    | (Только для JDBC) Таблица SQL Gateway Connection                                                                                                                                                                                                                                                                                                                                                                                                            |

Вот пример команды LOAD DATA:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
INTO MyTable
```

В данном случае колонки таблицы сортируются по [SqlColumnNumber](https://docs.intersystems.com/iris20212/csp/docbook/DocBook.UI.Page.cls?KEY=ROBJ_property_sqlcolumnnumber) а колонки файла по алфавиту.
Поэтому в большинстве случаев следует явно указывать колонки, например:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
COLUMNS (head1 INT,head2 VARCHAR(20),head3 INT,head4 VARCHAR(20),head5 INT)
INTO MyTable(field1,field3) VALUES (head2,head5)
```

##  Формат данных

Файл c данными должен содержать все поля, указанные в `INTO`.

- Каждая строка в файле данных определяет отдельную запись (строку). Перевод строки (```\n```) является разделителем строк по умолчанию. Пустые строки игнорируются.
- Вы можете задать другой разделитель строк, указав параметр `lineseparator` в части `USING`. Доступные значения: `\n`, `\r` или `\r\n`.
- Значения данных в записи разделяются символом-разделителем столбцов. Запятая является символом-разделителем столбцов по умолчанию. Все поля данных должны быть обозначены разделителями столбцов, включая отсутствующие данные, обозначенные разделителями столбцов. Вы можете задать другой символ-разделитель столбцов, указав параметр `columnseparator` в части `USING`.
- По умолчанию экранирование символов не определено. Чтобы включить символ-разделитель столбцов в качестве литерала в значение данных, поместите значение данных в кавычки `"`. Чтобы включить кавычки в данные, заключенное в кавычки, удвойте символ кавычек (`""`). Вы можете задать экранирующий символ явно, указав параметр `escapechar` в части USING.
- Все данные проверяются на соответствие критериям таблицы, включая количество полей данных в записи, тип данных и длину каждого поля. Запись файла данных, не прошедшая проверку, пропускается. Сообщение об ошибке записывается в таблицу `%SQL_Diag.Message`. Загрузка данных продолжается со следующей записи.
- По умолчанию значения данных указываются в порядке следования полей в таблице (или представлении). Вы можете использовать предложение COLUMNS, чтобы указать данные в другом порядке. Вы можете использовать представление для загрузки записи данных в таблицу, предоставив только значения для полей, которые определены в представлении.

## USING

Условие `USING` позволяет настроить работу LOAD DATA. Вот все доступные настройки:

| Параметр       | Описание                                                                                                                                                                                                            | Пример | Значение по умолчанию |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------ | --------------------- |
| lineseparator   | whether to treat "\\n", "\\r" or "\\r\\n" as the line separator (these are the only allowed values)                                                                                                                 | "\\n"  | \\n                   |
| charset         | Кодировка                                                                                                                                                                                                           | UTF-8  | NLS настройка сервера |
| columnseparator | Разделитель колонок                                                                                                                                                                                                 | ;      | ,                     |
| escapechar      | Символ экранирования                                                                                                                                                                                                | \\\\   | не определено         |
| header          | Содержит ли первая строка CSV имена столбцов? Если установлено значение true, имена столбцов, взятые из этой строки заголовка, могут быть использованы в предложении VALUES, если не указано явное условие COLUMNS. | true   | false                 |
| skip            | Сколько строк нужно пропустить после заголовка (если header указано как true)                                                                                                                                       | 2      | 0                     |

Пример вызова LOAD DATA со всеми настройками:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
INTO Sample.Employees
USING {
	"from": {
		"file": {
			"columnseparator": "^",
			"lineseparator": "\r\n",
			"escapechar": "\\",
			"header": "1",
			"skip": "2",
			"charset": "UTF-8"
		}
	}
}
```

## Заголовок

Файл данных может дополнительно содержать строку заголовка, например:

```csv
Name,Department,Country,City,Street
Frank Rogers,Administration,USA,Cambridge,1 Memorial Drive
...
```

Чтобы указать, что файл данных имеет строку заголовка, используйте параметр header, как показано в следующем примере:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
INTO Sample.Employees
USING {"from":{"file":{"header":"1"}}}
```

Параметр `header` принимает значение 1 (True). Это идентифицирует первую строку файла данных как строку заголовка, которая не должна загружаться как данные. По умолчанию строка заголовка отсутствует; все строки считаются данными.

Примечание: Если вы не укажете параметр `header`, строка заголовка может быть не загружена в качестве записи таблицы, поскольку текст заголовка не проходит проверку на соответствие типу данных поля (например, целочисленное поле с заголовком "Всего"). Однако не следует полагаться на это. Используйте параметр `header`.

Если вы установили параметр `header` равным 1, вы можете дополнительно установить параметр `skip` - целое число. Параметр `skip` пропускает дополнительные строки, следующие непосредственно за заголовком. В следующем примере не загружаются первые 3 строки файла данных (строка заголовка и 2 дополнительные пропущенные строки):

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
INTO Sample.Employees
USING {"from":{"file":{"header":"1","skip":"2"}}}
```

Если параметр `header` не указан или равен 0, и вы установили параметр `skip`, то вызов `LOAD DATA` завершается успешно, но ничего не загрузит.

Если значения заголовка совпадают с именами полей таблицы, то `LOAD DATA` автоматически сопоставляет элементы файла данных с соответствующими полями таблицы. Например, если последовательность заголовков - `Department,Name,Country,City,StreetAddress`, а последовательность полей таблицы - `Name,Department,StreetAddress,City,Country`, то следующий пример сопоставляет столбцы заголовков с соответствующими полями таблицы:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
INTO Sample.Employees
USING {"from":{"file":{"header":"1"}}}
```

Если же значения заголовков не совпадают с именами полей таблицы для `LOAD DATA` требуется условие `COLUMNS`, чтобы сопоставить элементы файла данных с соответствующими полями таблицы. Например, если последовательность заголовков - `Dept,FullName,Nation,City,Street`, а последовательность полей таблицы - `Name,Department,StreetAddress,City,Country`, то следующий пример сопоставляет столбцы файла с соответствующими полями таблицы:

```sql
LOAD DATA FROM FILE 'C://TEMP/mydata.txt' 
COLUMNS (Department VARCHAR(40),Name VARCHAR(40)),Country VARCHAR(20),City VARCHAR(20),StreetAddress VARCHAR(20)) 
INTO Sample.Employees
USING {"from":{"file":{"header":"1"}}}
```

Как видите, последовательность COLUMNS - это последовательность строк заголовка, а имена COLUMNS - это имена полей таблицы.

## Даты (и любые другие функциональные преобразования)

В InterSystems IRIS даты хранятся в формате [$horolog](https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=RCOS_vhorolog). LOAD DATA ожидает даты в ODBC формате (yyyy-mm-dd).
Если даты в другом формате (или необходимо выполнить произвольное функциональное преобразование), можно использовать 2 подхода:

1. Временное и вычисляемое свойства. Допустим у нас даты в формате `12/01/2021` (`dd/mm/yyyy`). Создадим 2 свойства:

```
Property InputDate As %String;

Property MyDate As %Date [ SqlComputeCode = { set {*} = $ZDH({InputDate},4)}, SqlComputed, SqlComputeOnChange = InputDate ];
```

`InputDate` будет заполняться функцией LOAD DATA (это строка и соответственно никаких проблем с форматом не будет), а свойство `MyDate` будет автоматически вычисляться при каждом изменении `InputDate`.
Недостатком данного подхода является необходимость хранить оба свойства.

2. Классы типов данных. В InterSystems IRIS можно создавать свои [типы данных](https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=RSQL_datatype#RSQL_datatype_userdef):

```objectscript
Class User.MyDate Extends %Date
{

ClassMethod OdbcToLogical(%val As %String = "") As %Date [ CodeMode = generator, ServerOnly = 1 ]
{
	$$$GENERATE(" quit:%val=""""||($zu(115,13)&&(%val=$c(0))) """" quit:$isvalidnum(%val,0,-672045,2980013) %val set %val=$zdateh(%val,4,,,,,-672045,,""Error: '""_%val_""' is an invalid dd/mm/yyyy Date value"") q:%val||(%val=0) %val s %msg=%val ZTRAP ""ODAT""")
}

}
```

После компиляции класса и регистрации соответствующего ему SQL типа данных его можно использовать при вызове LOAD DATA.

## Логирование и ошибки

Успешный вызов LOAD DATA создает запись в таблице ```%SQL_Diag.Result``` и таблице ```%SQL_Diag.Message```. 

```sql
SELECT * FROM %SQL_Diag.Result
```

В столбце ```errorCount``` таблицы ```%SQL_Diag.Result```  указано количество записей, которые не удалось загрузить.

В таблице ```%SQL_Diag.Message``` содержится подробная информация о каждой записи, которую не удалось загрузить.

```sql
SELECT * FROM %SQL_Diag.Message WHERE severity = 'error'
```

Обратите внимание, что метка времени в этих таблицах хранится в формате UTC, а не местном времени.

# %SQL_Util.CSV

[SQL процедура](https://docs.intersystems.com/irislatest/csp/documatic/%25CSP.Documatic.cls?LIBRARY=%25SYS&CLASSNAME=%25SQL.Util.Procedures#CSV) для быстрого просмотра CSV файлов. Также применяется в случаях, когда требуются многочисленные манипуляции с исходными данными или исходные данные хранятся в потоке а не в файле. Например

```
CALL %SQL_Util.CSV(,'ROW(MYID VARCHAR(10000), FIXED VARCHAR(10000))','C://TEMP/mydata.txt',';',,'CP1251')
```

Процедура принимает следующие параметры:

| Параметр        | Описание                                                                                                                                                                                                                      |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| pSelectMode     | Формат данных. Допустимые значения: 0 - логический, 1 - ODBC и 2 - отображение.                                                                                                                                               |
| pRowType        | Описание данных. Если аргумент pRowType не передан или передан как null, то ожидается, что тип строки будет первой строкой файла данных. Если pRowType передан, то любое встроенное значение типа ряда будет проигнорировано. |
| pFileName       | Имя файла, содержащего данные. Это также может быть поток (stream).                                                                                                                                                           |
| pDelimiter      | Символ-разделитель csv. По умолчанию это запятая.                                                                                                                                                                             |
| pQuote          | Символ кавычек. По умолчанию - двойная кавычка. Этот символ используется для разделения значений, которые могут содержать символ разделителя значений или другие управляющие символы.                                         |
| pTranslateTable | Кодировка входного файла. Если она не указана, то будет использоваться таблица трансляции по умолчанию. Если pFileName является потоком, то этот аргумент игнорируется.                                                       |

Эта SQL-процедура/метод создает resultset, связанный с источником данных. Набор результатов возвращается как динамический набор результатов в объекте контекста процедуры. Любые строки в CSV файле, начинающиеся с `--`, считаются комментариями и пропускаются. Столбцы из источника данных формируют строку результата. Структура строки результата определяется из параметра `pRowType`. Формат дескриптора строки представляет собой список определений полей через запятую, где каждое определение поля содержит имя поля и тип данных. Имя поля и тип данных соответствуют правилам, используемым для определений полей в операторе CREATE TABLE. Например:

`StateFips VARCHAR(2),Zip_Code VARCHAR(5),State_Abbr VARCHAR(2),Name VARCHAR(200),Longitude_West Numeric(10,6),Latitude_North Numeric(10,6)`

Дескрипторы строрки обычно не допускают определения отсутствующих (пустых) полей, но для цели описания записей CSV файла пустые поля допускаются и указывают на игнорируемый столбец в источнике данных. В приведенном ниже примере первые два столбца и четвертый столбец игнорируются:

```
,,Zip_Code VARCHAR(5),,Name VARCHAR(200),Longitude_West Numeric(10,6),Latitude_North Numeric(10,6)
```

Нет необходимости добавлять дополнительные запятые для указания колонок, пропущенных в конце.

Дескриптор типа строки может быть встроен во входной файл. Просто добавьте строку в начале файла в качестве комментария, содержащего тип строки. Например:

```
--ROW(,,Zip_Code VARCHAR(5),,Name VARCHAR(200),Longitude_West Numeric(10,6),Latitude_North Numeric(10,6)).
```

Встроенный дескриптор строки игнорируется, если вызывающая программа явно передает `pRowType`.

Эта утилита может быть вызвана как хранимая процедура, либо с помощью динамического SQL. Например: 

```objectscript
set rowtype = "State VARCHAR(2),Zip_Code VARCHAR(5),State_Abbr VARCHAR(2),Name VARCHAR(200),Longitude_West Numeric(10,6),Latitude_North Numeric(10,6)"
set filename = "/Users/test/Documents/zip.csv"
set result = ##class(%SQL.Statement).%ExecDirect(,"call %SQL_Util.CSV(,?,?)",.rowtype,.filename)
set resultSet = result.%NextResult()
write resultSet.%Next()
write resultSet.State
```

# %SQL_Util.CSVTOCLASS

[SQL процедура](https://docs.intersystems.com/irislatest/csp/documatic/%25CSP.Documatic.cls?LIBRARY=%25SYS&CLASSNAME=%25SQL.Util.Procedures#CSVTOCLASS) аналогична предыдущей, но генерирующая хранимый класс данных соответствующий дескриптору строки и метод `Import`. Добавляет ряд параметров, связанных с генерацией хранимого класса:

| Параметр     | Описание                                                                                                                                                                                                                                                                 |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| pHeaderCount | Количество записей, которые будут пропущены в начале файла.                                                                                                                                                                                                              |
| pClassName   | Имя класса, в который будут импортированы данные. Если этот класс еще не существует, то он будет создан на основе десткиптора строки. Если этот класс уже существует, то предполагается, что определение класса соответствует типу строки и что реализован метод Import. |
| pTableName   | Имя SQL-таблицы, для сгенерированного класса. Принимает значение, основанное на имени класса, если значение не передано.                                                                                                     |
# Record Mapper

Графический инструмент конфигурации парсеров CSV файлов, [Record Mapper](https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=EGDV_recmap) обеспечивает быстрый и эффективный способ сопоставления данных в текстовых файлах с сообщениями продукции (хранимыми классами) и наоборот. В частности, пользовательский интерфейс позволяет визуально создать представление текстового файла и создать  объектное представление этих данных, которое отображается на один объект - сообщение продукции. Процесс генерации как целевой структуры объекта, так и парсера автоматизирован. 
Портал управления также предоставляет CSV Wizard, который поможет вам преобразовать файлы CSV (Character Separated Value) в структуру record map. Это особенно полезно для файлов, содержащих заголовки столбцов, поскольку CSV Wizard использует имена заголовков для создания свойств record map, соответствующих столбцам в файле данных.

Record Mapper записей работает с простыми записями, которые либо разделены, либо имеют поля фиксированной длины. Record Map состоит из надора полей, которые идентифицируют данные в записи, и композитов, которые организуют поля в единое целое. В разделенных записях иерархический уровень композитов определяет разделитель, который используется между полями. В разделенных записях можно задавать повторяющиеся простые поля. При желании можно игнорировать поля во входящем текстовом файле, чтобы они не занимали место в базе данных.

![image](https://user-images.githubusercontent.com/5127457/149316433-aca54845-2a03-4c39-95f1-40b901df3119.png)

# Глобалы

Этот подход использует возможности InterSystems IRIS как [мультимодельной базы данных](https://community.intersystems.com/post/classes-tables-and-globals-how-it-all-works). 
Подход заключается в:

1. Создании хранимого класса со схемой хранения аналогичной CSV файлу.
2. Написанию метода `Import`.

Приведу небольшой пример. Допустим у нас есть CSV с точками - двумя колонками X и Y:

```csv
X,Y
1,4
7,0
```

Создадим класс:

```objectscript
Class try.Point Extends %Persistent
{
Property X As %Integer;
Property Y As %Integer;
}
```

Аналогичный класс можно создать с помощью SQL:

```sql
CREATE Table try.Point (X INT, Y INT)
```

При компиляции класса `try.Point` будет создано определение хранилища - маппинг между глобалами и объектной и реляционной моделями:

```xml
<Data name="PointDefaultData">
    <Value name="1">
        <Value>%%CLASSNAME</Value>
    </Value>
    <Value name="2">
        <Value>X</Value>
    </Value>
    <Value name="3">
        <Value>Y</Value>
    </Value>
</Data>
<DataLocation>^try.PointD</DataLocation>
<DefaultData>PointDefaultData</DefaultData>
<IdLocation>^try.PointD</IdLocation>
<IndexLocation>^try.PointI</IndexLocation>
<StreamLocation>^try.PointS</StreamLocation>
<Type>%Library.CacheStorage</Type>
```

Нам здесь интересен `DataLocation` - глобал, в котором хранятся данные (`^try.PointD`) и `PointDefaultData` определяющая порядок хранения полей. В нашем случае поля 3:

- 1 - %%CLASSNAME
- 2 - X
- 3 - Y

Записи в глобале должны соответствовать данной структуре:

```objectscript
^try.PointD(id) = $lb("", X, Y)
```

Теперь напишем метод метод `Import`:

```objectscript
ClassMethod Import(file) As %Status
{
  #dim sc As %Status = $$$OK
  set stream = ##class(%Stream.FileCharacter).%New()
  set sc = stream.LinkToFile(file)
  quit:$$$ISERR(sc) sc
  
  do stream.ReadLine() // Пропускаем заголовок
  
  while 'stream.AtEnd {
    set line = stream.ReadLine()
    set ^try.PointD($i(^try.PointD)) = $lb("") _ $lfs(line, ",")
  }
  kill stream
  
  quit sc
}
```

Конечно, метод может быть намного сложнее и включать конверсию и валидацию данных и т.п., но общей смысл думаю ясен.

Преимуществом данного подхода является скорость вставки данных.

# Выводы

[LOAD DATA](https://docs.intersystems.com/iris20212/csp/docbook/DocBook.UI.Page.cls?KEY=RSQL_loaddata) позволяет легко импортировать CSV файлы в хранимые таблицы InterSystems IRIS.

# Ссылки

- [LOAD DATA](https://docs.intersystems.com/iris20212/csp/docbook/DocBook.UI.Page.cls?KEY=RSQL_loaddata) 
- [%SQL_Util](https://docs.intersystems.com/irislatest/csp/documatic/%25CSP.Documatic.cls?LIBRARY=%25SYS&CLASSNAME=%25SQL.Util.Procedures#CSVTOCLASS) 
- [Record Mapper](https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=EGDV_recmap)
- [Конкурс наборов данных](https://openexchange.intersystems.com/contest/20), на котором представлено много примеров работы с LOAD DATA
